{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries, set options to display all columns in dataframes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial, reduce \n",
    "#import re\n",
    "#import requests\n",
    "#from bigfloat import *\n",
    "#from lxml import html\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Data loading and preparing\n",
    "###\n",
    "# Load financial data\n",
    "sub = pd.read_csv(\"data/2019q1//sub.txt\", sep='\\t')# parsedates=['accepted'])) \n",
    "pre = pd.read_csv(\"data/2019q1/pre.txt\", sep='\\t') \n",
    "num = pd.read_csv(\"data/2019q1/num.txt\", sep='\\t')#, parsedates=['ddate']) \n",
    "tag = pd.read_csv(\"data/2019q1/tag.txt\", sep='\\t') \n",
    "\n",
    "sub = sub.append(pd.read_csv(\"data/2019q2/sub.txt\", sep='\\t'))\n",
    "pre = pre.append(pd.read_csv(\"data/2019q2/pre.txt\", sep='\\t'))\n",
    "num = num.append(pd.read_csv(\"data/2019q2/num.txt\", sep='\\t'))#, parsedates=['ddate']))\n",
    "\n",
    "sub = sub.append(pd.read_csv(\"data/2019q3/sub.txt\", sep='\\t'))\n",
    "pre = pre.append(pd.read_csv(\"data/2019q3/pre.txt\", sep='\\t'))\n",
    "num = num.append(pd.read_csv(\"data/2019q3/num.txt\", sep='\\t'))\n",
    "\n",
    "sub = sub.append(pd.read_csv(\"data/2018q1/sub.txt\", sep='\\t'))\n",
    "pre = pre.append(pd.read_csv(\"data/2018q1/pre.txt\", sep='\\t'))\n",
    "num = num.append(pd.read_csv(\"data/2018q1/num.txt\", sep='\\t'))#, parsedates=['ddate']))\n",
    "\n",
    "sub = sub.append(pd.read_csv(\"data/2018q2/sub.txt\", sep='\\t'))\n",
    "pre = pre.append(pd.read_csv(\"data/2018q2/pre.txt\", sep='\\t'))\n",
    "num = num.append(pd.read_csv(\"data/2018q2/num.txt\", sep='\\t'))#, parsedates=['ddate']))\n",
    "\n",
    "sub = sub.append(pd.read_csv(\"data/2018q3/sub.txt\", sep='\\t'))\n",
    "pre = pre.append(pd.read_csv(\"data/2018q3/pre.txt\", sep='\\t'))\n",
    "num = num.append(pd.read_csv(\"data/2018q3/num.txt\", sep='\\t'))#, parsedates=['ddate']))\n",
    "\n",
    "sub = sub.append(pd.read_csv(\"data/2018q4/sub.txt\", sep='\\t'))\n",
    "pre = pre.append(pd.read_csv(\"data/2018q4/pre.txt\", sep='\\t'))\n",
    "num = num.append(pd.read_csv(\"data/2018q4/num.txt\", sep='\\t'))#, parsedates=['ddate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean ticker and ciks\n",
    "ciks = pd.read_csv('data/ticker_cik.csv')\n",
    "ciks.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ciks with subs, select necessary columns from submission dataframes\n",
    "new_sub = pd.merge(left=ciks, right=sub, left_on='cik', right_on='cik')\n",
    "new_sub = new_sub[['ticker', 'adsh', 'name', 'form', 'period', 'fp', 'fy', 'filed']]\n",
    "new_num = num[['adsh', 'tag', 'version', 'ddate', 'qtrs', 'value', 'footnote']]\n",
    "new_pre = pre[['adsh', 'line', 'stmt', 'tag', 'plabel', 'negating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge new submission dataframes into on dataframe -- merged_items\n",
    "sub_pre = pd.merge(left=new_sub, right=new_pre, on='adsh' )\n",
    "merged_items = pd.merge(left=sub_pre, right=new_num, on=['adsh', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_items.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# End of loading and preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select company submissions using ticker\n",
    "def find_company_submissions(ticker):\n",
    "    comp_sub = merged_items[merged_items['ticker']== ticker]\n",
    "    return(comp_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe based on statement\n",
    "def filter_statement(comp_df, stmt):\n",
    "    comp_statement = comp_df[comp_df['stmt'] == stmt]\n",
    "    return(comp_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_stmt_subs(comp_stmt):\n",
    "    adsh_nums = comp_stmt['adsh'].unique()\n",
    "    sngl_sub_list = []\n",
    "    \n",
    "    for num in adsh_nums:\n",
    "        sngl_sub = comp_stmt[comp_stmt['adsh'] == num]\n",
    "        sngl_sub_list.append(sngl_sub)\n",
    "    return(sngl_sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table from the company statement\n",
    "#def make_pivot_table(stmt_df):\n",
    "#    pv_table = stmt_df.pivot_table(index=['adsh', 'stmt', 'fp', 'form', 'qtrs', 'version', 'filed', 'line','negating',\n",
    "#                                          'plabel', 'tag'], columns=['ddate'], values = 'value')\n",
    "#    return(pv_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filings that have values reflection only 1 quarter\n",
    "def get_quarterly_values(cln_list):\n",
    "    quarterly_results = []\n",
    "    for stmt in cln_list:\n",
    "        quarterly_statement = stmt.xs(1)\n",
    "        quarterly_results.append(quarterly_statement)\n",
    "    return(quarterly_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Clean pivot table for combining\n",
    "# Create pivot table from the company statement\n",
    "def make_pivot_table(stmt_df):\n",
    "    pv_table = stmt_df.pivot_table(index=['adsh', 'stmt', 'qtrs', 'ddate', 'form', 'version', 'filed', 'line','negating',\n",
    "                                          'plabel', 'tag'], columns=['fp'], values = 'value')\n",
    "    return(pv_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list_of_pivot_tables(comp_list):\n",
    "    pivoted_stmt_list = []\n",
    "    for sub in comp_list:\n",
    "        pv_stmt = make_pivot_table(sub)\n",
    "        pivoted_stmt_list.append(pv_stmt)\n",
    "    pivoted_stmt_list[1]\n",
    "    pivoted_stmt_list[0].append(pivoted_stmt_list[1])\n",
    "    return(pivoted_stmt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Clean pivot table for combining\n",
    "### REVIST HOW TO HANDLE NEGATING\n",
    "def clean_pivot_table(pvt_tb):\n",
    "    clean_pv_tb = pvt_tb.reset_index(['adsh', 'stmt', 'negating'], drop=True)\n",
    "    return(clean_pv_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filings that have values reflection only 1 quarter\n",
    "def get_quarterly_values(cln_list):\n",
    "    quarterly_results = []\n",
    "    for stmt in cln_list:\n",
    "        quarterly_statement = stmt.xs(1)\n",
    "        if quarterly_statement.index.get_level_values('form')[0] == '10-Q':\n",
    "            quarterly_results.append(quarterly_statement)\n",
    "        else:\n",
    "            pass\n",
    "    return(quarterly_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tables(tb_list):\n",
    "    comb_tb = reduce(lambda x, y: x.append(y, sort=False), tb_list[:5])\n",
    "    return(comb_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAY BE BETTER TO USE SUBMISSION DATE????\n",
    "def seperate_by_dd_date(df):\n",
    "    filings_by_ddate = []\n",
    "    for i in df.index.get_level_values('filed').unique().to_list():\n",
    "        filings_by_ddate.append(df.xs(i, level='filed'))\n",
    "    return(filings_by_ddate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dfs(seperated_df):\n",
    "    cleaned_list = []\n",
    "    for i in seperated_df:\n",
    "        tmp = i.dropna(axis=1).reset_index(['ddate'])\n",
    "        tmp2 = tmp.pivot(columns='ddate')\n",
    "        tmp3 = tmp2.reset_index(['form', 'line', 'plabel'], drop=True)\n",
    "        cleaned_list.append(tmp3)\n",
    "    return(cleaned_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['tsla', 'bke', 'wmt', 'f', 'bbby', 'mck']\n",
    "results = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    aapl = find_company_submissions(ticker)\n",
    "\n",
    "    aapl_is = filter_statement(aapl, 'IS')    \n",
    "    aapl_subs_list = split_stmt_subs(aapl_is)  \n",
    "    pv_tb = []\n",
    "    for i in aapl_subs_list:\n",
    "        tmp = make_pivot_table(i)\n",
    "        pv_tb.append(clean_pivot_table(tmp))\n",
    "\n",
    "    quarterly_results = get_quarterly_values(pv_tb)\n",
    "\n",
    "        \n",
    "    g = combine_tables(quarterly_results)\n",
    "  \n",
    "    filings_by_ddate = seperate_by_dd_date(g)\n",
    "    cleaned = clean_dfs(filings_by_ddate)\n",
    "    \n",
    "    v_2017 = []\n",
    "    v_other = []\n",
    "    for i in cleaned:\n",
    "        lvls = i.index.get_level_values(0).unique().to_list()\n",
    "        if 'us-gaap/2017' in lvls:\n",
    "            tmp = i.xs('us-gaap/2017', level='version')\n",
    "            v_2017.append(tmp)\n",
    "        else:\n",
    "            v_other.append(i)\n",
    "    for i in v_2017:\n",
    "        tmp = reduce(lambda x,y: pd.merge(x, y, on='tag'), v_2017)\n",
    "        results.append(tmp)\n",
    "    for i in v_other:\n",
    "        tmp = reduce(lambda x,y: pd.merge(x, y, on='tag'), v_other)\n",
    "        results.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results:\n",
    "    display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#def create_new_index\n",
    "\n",
    "lines_2017 = quarterly_results[4].index.get_level_values('line').to_list()[:-1] \n",
    "tags_2017 = quarterly_results[4].index.get_level_values('tag').to_list()[:-1]\n",
    "tup_2017 = tuple(zip(lines_2017,tags_2017))\n",
    "\n",
    "new_results = []\n",
    "for i in quarterly_results[:5]:\n",
    "    display(i.reset_index('filed'))\n",
    "    #i = i.unstack(1)\n",
    "    if i.index.values[0][0] == 'us-gaap/2018':\n",
    "        i.reset_index('version',drop=True, inplace=True)\n",
    "        i.index = pd.MultiIndex.from_tuples(tup_2017, names=['line', 'tag'])\n",
    "        new_results.append(i)\n",
    "    else:\n",
    "        i.drop(index='CommonStockDividendsPerShareDeclared', level = 1, inplace=True)\n",
    "        i.reset_index('version',drop=True, inplace=True)\n",
    "        new_results.append(i)\n",
    "\n",
    "#pd.concat(quarterly_results, axis=1, sort=False)\n",
    "g = reduce(lambda x, y: pd.merge(x, y, on=['tag', 'filed'], how='outer'), new_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
